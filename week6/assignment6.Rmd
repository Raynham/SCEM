---
title: "assginment6"
author: "Ruinan Wang"
date: "10/11/2021"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## 1 A Gaussian model for Red tailed hawks
```{r}
library(Stat2Data)
library(dplyr)
library(tidyr)
library(ggplot2)
library(purrr)
data("Hawks")

RedTailedDf <- Hawks %>%
  filter(Species=="RT") %>%
  select(Weight,Tail,Wing)

head(RedTailedDf)

kernel_tail <- RedTailedDf%>%
  pull(Tail)

n <- length(kernel_tail)
mu_mle_tail <- mean(RedTailedDf$Tail,na.rm = 1)
sigma_mle_tail <- sd(RedTailedDf$Tail, na.rm = 1)*sqrt((n-1)/n)

mu_mle_tail

sigma_mle_tail

colors <- c("MLE density" = "red", "Kernel density"="blue")

Tails <- seq(mu_mle_tail-3*sigma_mle_tail,mu_mle_tail+3*sigma_mle_tail, by=sigma_mle_tail*0.001)

ggplot()+geom_line(data=data.frame(Tail=Tails,Density=dnorm(Tails,mu_mle_tail,sigma_mle_tail)),aes(x=Tail,y=Density, color = "MLE density")) + geom_density(data=tibble(kernel_tail),aes(x=kernel_tail,color="Kernel density"))+labs(y="Density function (mm)", color="Estimator")+theme_bw()+scale_color_manual(values=colors)
```


## 2 Location estimators with Gaussian data
```{r}
set.seed(0)
num_trials_per_sample_size<-100
min_sample_size<-5
max_sample_size<-1000
sample_size_inc<-5
mu_0<-1
sigma_0<-3

simulation_df<-crossing(trial=seq(num_trials_per_sample_size), sample_size=seq(min_sample_size, max_sample_size,sample_size_inc))%>% # create data frame of all pairs of sample_size and trial
  mutate(simulation=pmap(.l=list(trial,sample_size),.f=~rnorm(.y,mean=mu_0,sd=sigma_0)))%>% # simulate sequences of Gaussian random variables
  mutate(sample_md=map_dbl(.x=simulation,.f=median))%>% # compute the sample medians
  mutate(sample_mean = map_dbl(.x=simulation, .f=mean))%>%
  group_by(sample_size)%>%
  summarise(msq_error_md=mean((sample_md-mu_0)^2), msq_error_mean1=mean((sample_mean-mu_0)^2),msq_error_mean2=(mean(sample_mean)-mu_0)^2+(mean(sample_mean-mean(sample_mean)))^2)

head(simulation_df)



simulation_df%>%
  pivot_longer(cols=-sample_size,names_to="Estimator",values_to="msq_error")%>%
  mutate(Estimator=case_when(Estimator=="msq_error_md"~"Median",Estimator=="msq_error_mean1"~"Mean1",Estimator=="msq_error_mean2"~"Mean2"))%>%
  ggplot(aes(x=sample_size,y=msq_error,color=Estimator,linetype=Estimator))+geom_smooth()+theme_bw()+xlab("Sample size")+ylab("Mean square error")


simulation_df <- simulation_df%>%
  pivot_longer(cols= - sample_size,names_to = "Estimator", values_to="value")
simulation_df$Estimator <-factor(simulation_df$Estimator,levels = c('msq_error_mean1','msq_error_mean2','msq_error_md'),labels=c("Mean1","Mean2","Meidan"))
ggplot(data=simulation_df, aes(x=sample_size,y=value,color = Estimator, linetype=Estimator))+geom_point()+geom_smooth() +theme_bw() + xlab("Sample size")+ylab("Mean Square Error")+ylim(0,1)
```

## 3  Unbiased estimation of the population variance


### First, let's suppose we have a $X$ with a Gaussian Distribution ~ $N (1,3)$, here are the simulation study
```{r}
set.seed(0)
num_trials_per_sample_size<-1000
min_sample_size<-5
max_sample_size<-100
sample_size_inc<-5
mu_0<-1
sigma_0<-3
simulation_df <- crossing (trial=seq(num_trials_per_sample_size),sample_size=seq(min_sample_size,max_sample_size,sample_size_inc)) %>%
  mutate(simulation=pmap(.l=list(trial,sample_size),.f=~rnorm(.y,mean=mu_0,sd=sigma_0)))%>%
  mutate(sample_variance_MLE=pmap_dbl(.l=list(.x=simulation,.y=sample_size),.f=~(var(.x)*(.y-1)/.y))) %>%
  mutate(sample_variance_U=map_dbl(.x=simulation,.f=var))%>%
  group_by(sample_size)%>%
  summarise(bias_variance_MLE= (mean(sample_variance_MLE)-sigma_0^2), bias_variance_U= (mean(sample_variance_U)-sigma_0^2))

simulation_df

simulation_df <- simulation_df%>%
  pivot_longer(cols=-sample_size,names_to = "Estimator", values_to="value")

simulation_df$Estimator <-factor(simulation_df$Estimator,levels = c('bias_variance_MLE','bias_variance_U'),labels=c("Variance MLE","Variance U"))

ggplot(data=simulation_df, aes(x=sample_size, y=value, color=Estimator, linetype=Estimator)) +geom_smooth()+theme_bw()+labs(x="Sample Size", y="Bias Value")+ geom_hline(aes(yintercept=0),color="blue")

```

As we can see from the plot, the bias for variance U is more closed to 0, which means Variance U is more closed to the unbiased estimator.



## 5 Maximum likelihood estimation with the Poisson distribution


```{r}
set.seed(0)
num_trials_per_sample_size<-1000
min_sample_size<-5
max_sample_size<-100
sample_size_inc<-5
lambda_0 <- 0.5

simulation_poisson_df <- crossing(trial=seq(num_trials_per_sample_size),sample_size=seq(min_sample_size,max_sample_size,sample_size_inc)) %>%
  mutate(simulation = pmap(.l=list(trial,sample_size), ~rpois(.y,lambda_0)))%>%
  mutate(lambda_MLE = map_dbl(.x=simulation,.f=mean))%>%
  group_by(sample_size)%>%
  summarize(MSE_lambda = mean((lambda_MLE-lambda_0)^2))
head(simulation_poisson_df)
ggplot(data=simulation_poisson_df, aes(x=sample_size, y=MSE_lambda))+geom_smooth()+theme_bw()+xlab("Sample size")+ylab("Mean square error")
```


```{r}
bortkiewicz_horsekick_data <- read.csv("VonBortkiewicz.csv")
head(bortkiewicz_horsekick_data)
lambda_MLE <- mean(bortkiewicz_horsekick_data$fatalities)
lambda_MLE
prob_no_fatalities <- dpois(0,lambda_MLE)
prob_no_fatalities

set.seed(0)
lambda_0 <- 0.5
n <- 1000
sample_value <- rpois(n,lambda_0)
lambda_MLE <- mean(sample_value)
sample_value
lambda_MLE
```
### 6  Maximum likelihood estimation for the exponential distribution
```{r}
customer_purchase_time_data <- read.csv("CustomerPurchases.csv")
customer_purchase_time_data<- customer_purchase_time_data%>%
  mutate(time_diffs = lead(Time)-Time)
lambda_MLE <- 1/mean(customer_purchase_time_data$time_diffs, na.rm=TRUE)
lambda_MLE
prob_excess_60s<- 1-pexp(60,lambda_MLE)
prob_excess_60s
```